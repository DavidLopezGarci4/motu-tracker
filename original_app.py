import streamlit as st
import pandas as pd
import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import os
import subprocess
import sys

# --- HACK DE DESPLIEGUE: INSTALAR NAVEGADORES ---
# Streamlit Cloud no tiene los navegadores instalados por defecto.
try:
    # Usamos subprocess para que espere a que termine la instalaci√≥n antes de seguir
    # Instalamos TODO (incluyendo headless-shell que es lo que fallaba)
    print("üîß Instalando navegadores Playwright...")
    subprocess.run([sys.executable, "-m", "playwright", "install"], check=True)
    print("‚úÖ Navegadores instalados correctamente.")
except Exception as e:
    print(f"‚ö†Ô∏è Error instalando navegadores: {e}")


# Configuraci√≥n de p√°gina con layout ancho para que quepa bien la tabla
st.set_page_config(page_title="Rastreador Master MOTU", page_icon="‚öîÔ∏è", layout="wide")

# --- UTILIDADES DE NORMALIZACI√ìN (NUEVO) ---
import requests
import re

# --- CONFIGURACI√ìN DE NAVEGADOR EST√ÅTICO (HEADERS STANDARD) ---
import json

HEADERS_STATIC = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
    "Accept-Language": "es-ES,es;q=0.9,en;q=0.8",
    "Referer": "https://www.google.com/"
}

def limpiar_titulo(titulo):
    """Normaliza el t√≠tulo para agrupar productos similares."""
    import re
    # Eliminar palabras clave comunes para agrupar
    t = titulo.lower()
    t = re.sub(r'masters of the universe|motu|origins|masterverse|figura|action figure|\d+\s?cm', '', t)
    t = re.sub(r'\s+', ' ', t).strip()
    return t.title()

# --- HELPER: JSON-LD EXTRACTOR ---
def extraer_datos_json_ld(soup, source_tag):
    """Intenta extraer productos de metadatos JSON-LD (SEO)."""
    productos = []
    scripts = soup.find_all('script', type='application/ld+json')
    
    for script in scripts:
        try:
            data = json.loads(script.string)
            # Normalizar a lista si es dict √∫nico
            if isinstance(data, dict):
                data = [data]
            
            for entry in data:
                # Caso 1: ItemList (Cat√°logos)
                if entry.get('@type') == 'ItemList' and 'itemListElement' in entry:
                    for item in entry['itemListElement']:
                        # A veces el producto est√° directo, a veces en 'item'
                        prod = item.get('item', item)
                        if not isinstance(prod, dict): continue
                        
                        titulo = prod.get('name', 'Desconocido')
                        link = prod.get('url', 'No Link')
                        if link == 'No Link' and 'url' in item: link = item['url'] # Fallback
                        
                        image = prod.get('image', None)
                        if isinstance(image, list): image = image[0]
                        elif isinstance(image, dict): image = image.get('url')
                        
                        price = 0.0
                        price_str = "Ver Web"
                        
                        offers = prod.get('offers')
                        if isinstance(offers, dict):
                            price = float(offers.get('price', 0))
                            price_str = f"{price}‚Ç¨"
                        elif isinstance(offers, list) and offers:
                            price = float(offers[0].get('price', 0))
                            price_str = f"{price}‚Ç¨"
                            
                        # Filtro b√°sico
                        if "motu" not in titulo.lower() and "masters" not in titulo.lower(): continue
                        
                        productos.append({
                            "Figura": titulo,
                            "NombreNorm": limpiar_titulo(titulo),
                            "Precio": price_str,
                            "PrecioVal": price,
                            "Tienda": source_tag,
                            "Enlace": link,
                            "Imagen": image
                        })

                # Caso 2: Product Single (Ficha de producto - raro en listados pero posible)
                if entry.get('@type') == 'Product':
                    titulo = entry.get('name', 'Desconocido')
                    # ... (L√≥gica similar, simplificada por brevedad) ...
                    # En listados suele ser ItemList.
        except: continue
        
    return productos

# --- FUNCI√ìN 1: TRADEINN (Kidinn) ---
def buscar_kidinn():
    """Escanea Kidinn usando el endpoint de b√∫squeda (evita men√∫s vac√≠os)."""
    # Usamos el buscador interno que suele ser m√°s robusto ante bloqueos de navegaci√≥n
    url = "https://www.tradeinn.com/kidinn/es/buscar/products-ajax"
    params = {
        "search": "masters of the universe origins", # Consulta espec√≠fica
        "products_per_page": 48
    }
    
    log = [f"üåç Conectando a B√∫squeda Kidinn..."]
    
    try:
        r = requests.get(url, params=params, headers=HEADERS_STATIC, timeout=15)
        log.append(f"Status Code: {r.status_code}")
        
        soup = BeautifulSoup(r.text, 'html.parser')
        
        # ESTRATEGIA 1: JSON-LD (SEO DATA) - Los buscadores suelen tenerlo
        json_items = extraer_datos_json_ld(soup, "Kidinn")
        if json_items:
            log.append(f"‚úÖ JSON-LD encontr√≥ {len(json_items)} items. Usando datos estructurados.")
            # Ajuste de enlaces relativos
            for p in json_items:
                if not p['Enlace'].startswith('http'):
                    p['Enlace'] = "https://www.tradeinn.com" + p['Enlace']
            return {'items': json_items, 'log': log}
            
        log.append("‚ö†Ô∏è JSON-LD no encontr√≥ nada. Probando selectores HTML en b√∫squeda...")
        
        # ESTRATEGIA 2: HTML SCRAPING (FALLBACK)
        # En resultados de b√∫squeda, a veces cambia el selector.
        # Probamos selectores de grid de b√∫squeda
        items = soup.select('div.search-product-list-item, div.js-product-list-item, div.product-box')
        
        if not items:
            # Fallback selectors (Broad)
            items = soup.select('div.product-grid-item, div.search-product-item, div.item, div.item_container, div[data-id]')
            log.append(f"‚ö†Ô∏è Selector principal fall√≥. Fallbacks encontraron: {len(items)}")
            
            # √öltimo intento: Buscar enlaces directos de PRODUCTOS (terminan en /p)
            if not items:
                 # TradeInn usa /p para productos, /f para familias, /nm para nodos
                 potential_links = soup.select('a[href*="/p"]') 
                 # Filtramos para asegurar que son fichas de producto
                 items = []
                 for l in potential_links:
                     href = l.get('href', '')
                     # Debe tener /p y NO ser una paginaci√≥n o script, y tener algun ID num√©rico
                     if '/p' in href and re.search(r'\/\d+\/p', href):
                         # Evitamos enlaces de men√∫ que a veces se cuelan
                         if 'nav' not in l.get('class', []) and 'menu' not in l.get('class', []):
                             items.append(l.parent)
                             
                 # Deduplicar por link (a veces hay imagen + texto)
                 unique_items = []
                 seen_links = set()
                 for it in items:
                     lnk = it.select_one('a')['href']
                     if lnk not in seen_links:
                         unique_items.append(it)
                         seen_links.add(lnk)
                         
                 items = unique_items[:48]
                 log.append(f"‚ö†Ô∏è Fallback enlaces PRODUCTO (/p) encontr√≥: {len(items)}")

        log.append(f"Items a procesar: {len(items)}")
        
        productos = []
        items_procesados = 0
        for idx, item in enumerate(items):
            # Clonamos el item para no romper el original en debug
            debug_str = str(item)[:300]
            if idx == 0:
                log.append(f"üì¶ DEBUG HTML KIDINN ITEM 0: {debug_str}")
                
            try:
                # Link
                link_obj = item.select_one('a')
                if not link_obj: 
                    # Si el item mismo es el link
                    if item.name == 'a': link_obj = item
                    else: continue
                
                link = link_obj['href']
                if not link.startswith('http'): link = "https://www.tradeinn.com" + link

                # Title
                # Buscamos texto dentro del enlace o en hermanos
                titulo = link_obj.get_text(strip=True)
                if not titulo: 
                    # Intentar buscar imagen con alt
                    img = link_obj.find('img')
                    if img: titulo = img.get('alt', '')
                
                if not titulo: titulo = "Figura MOTU Desconocida"
                
                # Filtro RELAJADO: Si estamos aqui, el link ya tenia /p y venia de una busqueda de 'masters'
                # Solo filtramos si es claramente basura
                if "juguete" in titulo.lower() and len(titulo) < 15: continue
                
                # Price
                # Buscamos precio en el texto del padre
                full_text = item.get_text(separator=' ', strip=True)
                # Regex para buscar precio estilo 12,99 ‚Ç¨ o 12.99‚Ç¨
                price_match = re.search(r'(\d+[\.,]\d{2})\s?[‚Ç¨$]', full_text)
                
                precio = "Ver Web"
                precio_val = 9999.0
                
                if price_match:
                    precio = price_match.group(0)
                    try:
                        precio_val = float(price_match.group(1).replace(',','.'))
                    except: pass
                
                # Imagen
                img_obj = item.select_one('img')
                img_src = img_obj['src'] if img_obj else None
                
                productos.append({
                    "Figura": titulo,
                    "NombreNorm": limpiar_titulo(titulo),
                    "Precio": precio,
                    "PrecioVal": precio_val,
                    "Tienda": "Kidinn",
                    "Enlace": link,
                    "Imagen": img_src
                })
                items_procesados += 1
            except Exception as item_e:
                 continue
                 
        log.append(f"Kidinn: {items_procesados} items extra√≠dos.")
        return {'items': productos, 'log': log}
        
    except Exception as e:
        log.append(f"‚ùå Error Kidinn: {e}")
        return {'items': [], 'log': log}

# --- FUNCI√ìN 2: ACTION TOYS (API MODE) ---
def buscar_actiontoys():
    """Escanea ActionToys usando su API p√∫blica (WooCommerce)."""
    # Endpoint directo, sin parsear HTML. Mucho m√°s r√°pido y sin bloqueos.
    url_api = "https://actiontoys.es/wp-json/wc/store/products"
    params = {
        "search": "masters of the universe origins",
        "per_page": 50, # Pedimos 50 de una vez
        "page": 1
    }
    
    log = [f"üåç Consultando API ActionToys: {url_api}"]
    productos = []
    
    while True:
        try:
            r = requests.get(url_api, params=params, headers=HEADERS_STATIC, timeout=15)
            log.append(f"API P√°gina {params['page']} Status: {r.status_code}")
            
            if r.status_code != 200: break
            
            data = r.json()
            if not data: break # Fin de resultados
            
            log.append(f"API encontr√≥ {len(data)} items.")
            
            for item in data:
                try:
                    titulo = item.get('name', 'Desconocido')
                    # Filtro de seguridad
                    if "masters" not in titulo.lower() and "origins" not in titulo.lower(): continue
                    
                    price_data = item.get('prices', {})
                    # El precio viene en c√©ntimos (ej: 2249 -> 22.49) o string formateado
                    price_val = float(price_data.get('price', 0)) / 100.0
                    price_str = f"{price_val:.2f}‚Ç¨"
                    
                    link = item.get('permalink')
                    
                    # Imagen
                    images = item.get('images', [])
                    img_src = images[0].get('src') if images else None
                    
                    productos.append({
                        "Figura": titulo,
                        "NombreNorm": limpiar_titulo(titulo),
                        "Precio": price_str,
                        "PrecioVal": price_val,
                        "Tienda": "ActionToys",
                        "Enlace": link,
                        "Imagen": img_src
                    })
                except: continue
            
            # Paginaci√≥n
            if len(data) < params['per_page']: break # Si devuelve menos de los pedidos, es la √∫ltima
            params['page'] += 1
            if params['page'] > 5: break # L√≠mite de seguridad
            
        except Exception as e:
            log.append(f"‚ùå Error API ActionToys: {e}")
            break
            
    return {'items': productos, 'log': log}

# (Resto de c√≥digo antiguo borrado/comentado para evitar conflictos)


# --- ORQUESTADOR H√çBRIDO (ASYNC WRAPPER) ---
async def buscar_en_todas_async():
    """
    Ejecuta scrapers s√≠ncronos (requests) en hilos separados (asyncio.to_thread)
    para mantener el paralelismo y la velocidad.
    Combina resultados y logs.
    """
    # Lanzamos las dos funciones s√≠ncronas en paralelo usando hilos
    # Esto evita que una espere a la otra
    resultados = await asyncio.gather(
        asyncio.to_thread(buscar_kidinn),
        asyncio.to_thread(buscar_actiontoys)
    )
        
    # Aplanar resultados y agregar logs
    lista_productos = []
    lista_logs = []
    
    for res in resultados:
        lista_productos.extend(res['items'])
        lista_logs.extend(res['log'])
        
    return lista_productos, lista_logs

# --- CACH√â Y WRAPPER ---
# TTL = 3600 segundos (1 hora). show_spinner=False para controlar mensaje propio
@st.cache_data(ttl=3600, show_spinner=False)
def obtener_datos_cacheados():
    """Llamada s√≠ncrona cacheada."""
    return asyncio.run(buscar_en_todas_async())

# --- INTERFAZ ---
st.title("‚öîÔ∏è Buscador Unificado MOTU Origins")

# Estilos CSS Mejorados
st.markdown("""
<style>
    .stButton button { width: 100%; border-radius: 8px; font-weight: 600; }
    .card-container {
        border: 1px solid #ddd;
        border-radius: 12px;
        padding: 12px;
        background: white;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        height: 100%; /* Igualar alturas */
        display: flex;
        flex-direction: column;
        justify-content: space-between;
    }
    .price-tag {
        font-size: 1.1rem;
        font-weight: bold;
        color: #2e7bcf;
    }
    .store-row {
        display: flex;
        justify_content: space-between;
        align-items: center;
        margin-top: 5px;
        padding-top: 5px;
        border-top: 1px solid #eee;
    }
</style>
""", unsafe_allow_html=True)

# Bot√≥n Principal
col_btn1, col_btn2 = st.columns([3, 1])
if col_btn1.button("üöÄ RASTREAR OFERTAS", type="primary"):
    start = True
else:
    start = False

if col_btn2.button("üßπ LIMPIAR CACH√â"):
    st.cache_data.clear()
    st.toast("Memoria borrada. La pr√≥xima b√∫squeda ser√° fresca.", icon="üßπ")

if start:

    with st.spinner("‚ö° Escaneando el multiverso (Paralelo)..."):
        # Llamada a la funci√≥n con cach√©
        datos, logs_debug = obtener_datos_cacheados()
        
        if datos:
            df = pd.DataFrame(datos)
            
            # --- L√ìGICA DE AGRUPACI√ìN ---
            # Agrupamos por 'NombreNorm'
            grupos = df.groupby('NombreNorm')
            
            items_unicos = []
            
            for nombre, grupo in grupos:
                # Seleccionamos la mejor imagen (la primera que no sea None, o la primera del grupo)
                img_candidata = grupo['Imagen'].dropna().iloc[0] if not grupo['Imagen'].dropna().empty else None
                
                # Ordenamos las ofertas de este mu√±eco por precio
                ofertas = grupo.sort_values('PrecioVal').to_dict('records')
                
                # Precio m√≠nimo para mostrar "Desde X"
                precio_min = ofertas[0]['Precio']
                
                items_unicos.append({
                    "Nombre": nombre, # T√≠tulo limpio
                    "Imagen": img_candidata,
                    "PrecioMin": ofertas[0]['PrecioVal'],
                    "PrecioDisplay": precio_min,
                    "Ofertas": ofertas # Lista de diccionarios {Tienda, Precio, Enlace...}
                })
            
            # Ordenar los grupos por el precio m√°s bajo que tengan
            items_unicos.sort(key=lambda x: x['PrecioMin'])
            
            st.success(f"¬°Combate finalizado! {len(items_unicos)} figuras √∫nicas encontradas (de {len(df)} ofertas).")
            with st.expander("üìù Logs t√©cnicos (Click para ver)"):
                st.write(logs_debug)
                
            st.divider()

            # --- RENDERIZADO DE TARJETAS ---
            cols = st.columns(2)
            
            for idx, item in enumerate(items_unicos):
                with cols[idx % 2]:
                    with st.container(border=True):
                        # Imagen
                        if item['Imagen']:
                            st.image(item['Imagen'], use_container_width=True)
                        else:
                            st.markdown("üñºÔ∏è *Sin Imagen*")
                        
                        # T√≠tulo
                        st.markdown(f"#### {item['Nombre']}")
                        
                        # Lista de Ofertas (Comparador)
                        st.caption("Ofertas disponibles:")
                        
                        for oferta in item['Ofertas']:
                            # Dise√±o compacto por oferta: "Kidinn: 15‚Ç¨ [Link]"
                            c1, c2 = st.columns([2, 1])
                            c1.markdown(f"**{oferta['Tienda']}**: {oferta['Precio']}")
                            c2.link_button("Ir", oferta['Enlace'], help=f"Comprar en {oferta['Tienda']}")
                            
        else:
            st.error("‚ùå No se encontraron resultados.")
            
            # MOSTRAR LOGS EN PANTALLA PRINCIPAL SI FALLA
            st.warning("Parece que Skeletor ha bloqueado la conexi√≥n. Aqu√≠ tienes el informe t√©cnico:")
            with st.container(border=True):
                st.markdown("### üïµÔ∏è‚Äç‚ôÇÔ∏è Informe de Debugging")
                for linea in logs_debug:
                    if "‚ùå" in linea or "‚ö†Ô∏è" in linea:
                        st.error(linea)
                    else:
                        st.text(linea)

